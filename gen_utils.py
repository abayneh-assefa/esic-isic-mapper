# File: gen_utils.py

import os
import yaml
import requests
import json
import time
from dotenv import load_dotenv

# â”€â”€â”€ Load Environment & Config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
with open("config.yaml", "r") as f:
    config = yaml.safe_load(f)

OLLAMA_HOST = os.getenv("OLLAMA_HOST", config.get("ollama_host", "http://localhost:11434"))
VERBOSE = os.getenv("GEN_VERBOSE", "false").lower() == "true"
TIMEOUT = int(os.getenv("GEN_TIMEOUT", "300"))  # Adjustable

# â”€â”€â”€ Endpoint Resolver â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def resolve_endpoint(model_name: str):
    if model_name.endswith("-chat") or model_name.startswith(("gemma", "qwen")):
        return f"{OLLAMA_HOST}/api/chat", "chat"
    return f"{OLLAMA_HOST}/api/generate", "generate"

# â”€â”€â”€ Host Check (Optional) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def is_host_reachable(host_url):
    try:
        return requests.get(host_url, timeout=5).status_code < 400
    except:
        return False

# â”€â”€â”€ Unified Query Interface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def query_gen_model(prompt: str, model_name: str, retries: int = 0, delay: int = 2):
    endpoint, mode = resolve_endpoint(model_name)

    payload = {
        "model": model_name,
        "temperature": 0.3,
        "max_tokens": 1024,
        "stop": ["\n"]
    }

    if mode == "chat":
        payload["messages"] = [{"role": "user", "content": prompt.strip()}]
    else:
        payload.update({
            "prompt": prompt.strip(),
            "stream": False
        })

    for attempt in range(retries + 1):
        try:
            start = time.time()
            response = requests.post(endpoint, json=payload, timeout=TIMEOUT)
            response.raise_for_status()

            # â”€â”€â”€ Chat-style â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            if mode == "chat":
                data = response.json()
                if VERBOSE: print(f"ðŸ“¥ Chat response: {data}")
                return data.get("message", {}).get("content", "âš ï¸ No chat output.")

            # â”€â”€â”€ Generate-style â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
            data = response.json()
            final = data.get("response", "") or data.get("output", "")
            if VERBOSE: print(f"ðŸ“¥ Generate response in {time.time() - start:.2f}s: {final[:100]}...")
            return final.strip() or "âš ï¸ Empty generate output."

        except Exception as ex:
            print(f"âš ï¸ Attempt {attempt+1} failed: {ex}")
            if attempt < retries:
                time.sleep(delay)

    return "âŒ Generation failed after retries. Model may be overloaded or misrouted."


# # File: gen_utils.py

# import os
# import yaml
# import requests
# import json
# import time
# from dotenv import load_dotenv

# # â”€â”€â”€ Load Environment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# load_dotenv()

# with open("config.yaml", "r") as f:
#     config = yaml.safe_load(f)

# OLLAMA_HOST = os.getenv("OLLAMA_HOST", config.get("ollama_host", "http://localhost:11434"))
# VERBOSE = os.getenv("GEN_VERBOSE", "false").lower() == "true"

# # â”€â”€â”€ Endpoint Resolver â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# def resolve_endpoint(model_name: str):
#     if model_name.endswith("-chat") or model_name.startswith(("gemma", "qwen")):
#         return f"{OLLAMA_HOST}/api/chat", "chat"
#     return f"{OLLAMA_HOST}/api/generate", "generate"

# # â”€â”€â”€ Reachability Check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# def is_host_reachable(host_url):
#     try:
#         probe = requests.get(host_url, timeout=5)
#         reachable = probe.status_code < 400
#         if VERBOSE:
#             print(f"âœ… Host reachable: {host_url}")
#         return reachable
#     except Exception as e:
#         print(f"âŒ Host unreachable: {e}")
#         return False

# # â”€â”€â”€ Model Query with Fallbacks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# def query_gen_model(prompt: str, model_name: str, retries: int = 0, delay: int = 2):
#     # if not is_host_reachable(OLLAMA_HOST):
#     #     return "âš ï¸ Host unreachable. Check Docker/network settings."

#     endpoint, mode = resolve_endpoint(model_name)

#     payload = {
#         "model": model_name,
#         "temperature": 0.3,
#         # "max_tokens": 150,
#         "max_tokens": 250,
#         "stop": ["\n"],
       
#     }

#     if mode == "chat":
#         payload["messages"] = [{"role": "user", "content": prompt.strip()}]
#     else:
#         payload["prompt"] = prompt.strip()
#         payload["stream"] = False

#     for attempt in range(retries + 1):
#         try:
#             with requests.post(endpoint, 
#                                json=payload, 
#                                timeout=120, 
#                             #    stream=(mode == "generate")
#                                ) as response:
#                 response.raise_for_status()

#                 if mode == "chat":
#                     try:
#                         data = response.json()
#                         return data.get("message", {}).get("content", "âš ï¸ No response.")
#                     except Exception as decode_error:
#                         return f"âš ï¸ Chat parse failed: {decode_error}"

#                 output = []
#                 for line in response.iter_lines():
#                     if line:
#                         try:
#                             token = json.loads(line.decode("utf-8")).get("response", "")
#                             output.append(token)
#                         except Exception as stream_err:
#                             if VERBOSE:
#                                 print(f"âš ï¸ Stream decode error: {stream_err}")
#                 return "".join(output).strip() or "âš ï¸ Empty response."

#         except Exception as ex:
#             print(f"âš ï¸ Attempt {attempt+1} failed: {ex}")
#             if attempt < retries:
#                 time.sleep(delay)

#     return "âŒ Generation failed. Model may be overloaded or misconfigured."
